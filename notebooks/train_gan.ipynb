{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JaoPC\\AppData\\Local\\Temp\\ipykernel_15004\\3937769644.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import sys\n",
    "#making custom dataset class\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    " \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Module, Sequential, Conv2d, ConvTranspose2d, LeakyReLU, BatchNorm2d, ReLU, Tanh, Sigmoid, BCELoss \n",
    "%matplotlib inline\n",
    "#import sys\n",
    "#from ..src.pipeline import PredPipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'C:\\Repos\\TCC-CDIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training gan model in pytorch\n",
    "from src.gan import DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the image directory\n",
    "dir_data  = \"C:/Repos/TCC-CDIA/data/processed/outputs/semafaros/standard\"\n",
    "# setting image shape to 64x64\n",
    " \n",
    "# listing out all file names\n",
    "nm_imgs   = np.sort(os.listdir(dir_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['traffic_light_100_original(1).jpg', 'traffic_light_100_original.jpg', 'traffic_light_101_original(1).jpg', ..., 'traffic_light_99_original(1).jpg', 'traffic_light_99_original(2).jpg', 'traffic_light_99_original.jpg'], dtype='<U34')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() == True else 'cpu'\n",
    "# device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(imgs, grid_size = 5):\n",
    "    \"\"\"\n",
    "    imgs: vector containing all the numpy images\n",
    "    grid_size: 2x2 or 5x5 grid containing images\n",
    "    \"\"\"\n",
    "     \n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "    columns = rows = grid_size\n",
    "    plt.title(\"Training Images\")\n",
    " \n",
    "    for i in range(1, columns*rows +1):\n",
    "        plt.axis(\"off\")\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(imgs[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='C:/Repos/TCC-CDIA/data/processed/outputs/semafaros', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(dataloader, device)\n",
    "dcgan.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that `Generator` is the class name of your model\n",
    "from src.gan import Generator\n",
    "\n",
    "# Create an instance of the Generator model\n",
    "model = Generator()\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load('../models/dcgan/generator_final.pth', map_location=device))\n",
    "\n",
    "# Move the model to the same device as the input tensor\n",
    "model = model.to(device)\n",
    "\n",
    "# Generate random noise as input\n",
    "noise = torch.randn(64, 100, 1, 1, device=device)\n",
    "\n",
    "# Generate images\n",
    "with torch.no_grad():\n",
    "    generated_images = model(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that `Generator` is the class name of your model\n",
    "from src.gan import Generator\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Generator().to(device)\n",
    "model.load_state_dict(torch.load('../models/dcgan/generator_final.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Number of batches and batch size\n",
    "num_batches = 3\n",
    "batch_size = 64\n",
    "\n",
    "# Initialize tensor to hold generated images\n",
    "generated_images = torch.empty((0, 3, 64, 64)).to(device)\n",
    "\n",
    "# Generate images\n",
    "for _ in range(num_batches):\n",
    "    # Generate random noise as input\n",
    "    noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
    "\n",
    "    # Generate images\n",
    "    with torch.no_grad():\n",
    "        batch_images = model(noise)\n",
    "\n",
    "    # Append to the tensor of generated images\n",
    "    generated_images = torch.cat((generated_images, batch_images), 0)\n",
    "\n",
    "# Now generated_images contains num_batches * batch_size images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Assuming generated_images is a tensor of images\n",
    "generated_images = generated_images.detach().cpu().numpy()\n",
    "\n",
    "# Normalize images to [0,1] range\n",
    "generated_images = (generated_images + 1) / 2\n",
    "\n",
    "# Get the first num_batches * batch_size images\n",
    "imgs = generated_images[:num_batches * batch_size]\n",
    "\n",
    "# Number of images per figure\n",
    "images_per_figure = 64\n",
    "\n",
    "# Calculate the number of figures needed\n",
    "num_figures = math.ceil(len(imgs) / images_per_figure)\n",
    "\n",
    "for fig_num in range(num_figures):\n",
    "    # Get the images for this figure\n",
    "    fig_imgs = imgs[fig_num*images_per_figure:(fig_num+1)*images_per_figure]\n",
    "\n",
    "    # Create a grid of subplots\n",
    "    fig, axs = plt.subplots(8, 8, figsize=(10, 10))\n",
    "\n",
    "    for i, img in enumerate(fig_imgs):\n",
    "        # Calculate subplot position\n",
    "        row = i // 8\n",
    "        col = i % 8\n",
    "\n",
    "        # Plot the image\n",
    "        axs[row, col].imshow(np.transpose(img, (1, 2, 0)))\n",
    "        axs[row, col].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure in the models folder\n",
    "    plt.savefig(f'../models/generated_images_{fig_num}.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Number of batches and batch size\n",
    "num_images = 500\n",
    "batch_size = 64\n",
    "num_batches = num_images // batch_size + (num_images % batch_size != 0)\n",
    "\n",
    "# Initialize tensor to hold generated images\n",
    "generated_images = torch.empty((0, 3, 64, 64)).to(device)\n",
    "\n",
    "# Generate images\n",
    "for _ in range(num_batches):\n",
    "    # Generate random noise as input\n",
    "    noise = torch.randn(64, 100, 1, 1, device=device)\n",
    "\n",
    "    # Generate images\n",
    "    with torch.no_grad():\n",
    "        batch_images = model(noise)\n",
    "\n",
    "    # Append to the tensor of generated images\n",
    "    generated_images = torch.cat((generated_images, batch_images), 0)\n",
    "\n",
    "# Now generated_images contains num_batches * batch_size images\n",
    "\n",
    "# Convert tensor to PIL Images and save\n",
    "to_pil = transforms.ToPILImage()\n",
    "output_dir = '../data/processed/outputs/gan' \n",
    "os.makedirs('../data/processed/outputs/gan', exist_ok=True)\n",
    "\n",
    "for i, img in enumerate(generated_images):\n",
    "    # Normalize the image tensor to 0-1 range\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    pil_img = to_pil(img.cpu())  # Convert to PIL Image\n",
    "    try:\n",
    "        pil_img.save(f'{output_dir}/generated_image_{i+1}.jpg')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save image {i+1}: {e}\")  # Save the image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
